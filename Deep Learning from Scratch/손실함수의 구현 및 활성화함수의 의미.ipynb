{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc7710e",
   "metadata": {},
   "source": [
    "### Q. 활성화 함수를 사용하는 이유가 무엇일까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6eb4ad",
   "metadata": {},
   "source": [
    "A. 활성화 함수는 입력 신호의 총합을 출력신호로 변환하여서 다른 층의 뉴런으로 전달하게 되는데 그 과정에서 모델의 복잡도가 올라가게 된다. 선형의 퍼셉트론을 쌓아서는 해결할 수 없었던 문제들이 존재했고, 이것을 해결하기 위해 비선형함수를 활성화 함수에 도입하게 된다. 비선형 함수를 활성화 함수로 쓰는 것이 다층 퍼셉트론 즉, 신경망을 만드는 것에 의미가 있는 것이다. 단순히 선형의 활성화 함수를 쌓게 되면 안된다. 그렇다면 결국에 선형으로 귀결되기 때문에 비선형 문제를 풀기 위해서는 비선형 함수를 활성화 함수로 사용해야한다. 입력값에 대한 출력값이 비선형으로 나타나게 된다. \n",
    "- https://syj9700.tistory.com/37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6013de4",
   "metadata": {},
   "source": [
    "### 손실함수 : 신경망이 매개변수를 찾아나가는 기준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1ba0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차제곱함 : Sum of Squares for Error(SSE)\n",
    "import numpy as np\n",
    "def sum_squares_error(y,t):\n",
    "    return (np.sum((y-t)**2))/2\n",
    "# 왜 SSE를 구할 때는 2를 나눠야하는걸까? 경사하강법의 델타규칙에 의해서 어쩌고 저쩌고... 경사하강법 공부하고 돌아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "479b93f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1과 t의 SSE 0.09750000000000003\n",
      "y2과 t의 SSE 0.5975\n"
     ]
    }
   ],
   "source": [
    "# 원핫인코딩된 정답 레이블은 2\n",
    "t = [0,0,1,0,0,0,0,0,0,0]\n",
    "\n",
    "# y1은 2가 가장 높은 확률이라고, y2는 7이 가장 높은 확률이라고 나타남\n",
    "y1 = [0.1,0.05,0.6,0.0,0.05,0.1,0.0,0.1,0.0,0.0]\n",
    "y2 = [0.1,0.05,0.1,0.0,0.05,0.1,0.0,0.6,0.0,0.0]\n",
    "\n",
    "print(\"y1과 t의 SSE\",sum_squares_error(np.array(t),np.array(y1)))\n",
    "print(\"y2과 t의 SSE\",sum_squares_error(np.array(t),np.array(y2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af333abf",
   "metadata": {},
   "source": [
    "제대로 정답을 추론한 y2 넘파일 배열이 낮은 SSE 값을 가진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9b266af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1과 t의 CEE 0.510825457099338\n",
      "y2과 t의 CEE 2.302584092994546\n"
     ]
    }
   ],
   "source": [
    "# 교차엔트로피오차 : Cross Entropy Error(CEE)\n",
    "def cross_entropy_error(y,t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t*np.log(y+delta))\n",
    "\n",
    "print(\"y1과 t의 CEE\",cross_entropy_error(np.array(y1),np.array(t)))\n",
    "print(\"y2과 t의 CEE\",cross_entropy_error(np.array(y2),np.array(t)))\n",
    "# y가 0이 되면 log 0으로 inf가 되기 때문에 매우 작은 값인 delta 더해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9dadc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-f6e7c0610b57>:1: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d82f41b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
